{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8DFlhRpbSF2d4b3JIVCY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erofili-K/BI-BA/blob/main/BI_Ask1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1η εργασία Επιχειρησιακής Έρευνας & Ευφυΐας\n",
        "\n",
        "Όνομα: Ερωφίλη Κώνστα\n",
        "\n",
        "ΑΕΜ: 3618\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Άσκηση 1:**\n",
        "<br>\n",
        "Πρώτα, κατεβάζω τα δεδομένα (dataset) και τα φορτώνω σε σε ένα Pandas DataFrame. Στην συνέχεια χρησιμοποιώ την describe() για να δω κάποιες μετρικές και το πώς είναι κατανεμημένα τα δεδομένα μέσα στο dataset.\n",
        "<br>\n",
        "Η μεταβλητή \"ds\" περιέχει το dataset της εργασίας."
      ],
      "metadata": {
        "id": "8EloaT58BmJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p35Esp07BjlZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "#dataset\n",
        "!gdown --id 1qklC6HBqynRmhn5q-zY3Ov2a0jcCwT9s\n",
        "\n",
        "ds = pd.read_csv(\"/content/GroceriesInitial.csv\", delimiter=',', header='infer')\n",
        "dataf=ds\n",
        "print(f\"This dataset has {ds.shape} rows and collumns\")\n",
        "ds.head(n=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.describe()\n"
      ],
      "metadata": {
        "id": "3DiVpUe6Vu4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το πρώτο πράγμα πριν αρχίσω την επεξεργασία των δεδομένων και προχωρήσω στις ασκήσεις είναι να κάνω οπτικοποίηση των δεδομένων.\n",
        "<br>\n",
        "Για αυτό χρησιμοποιώ τις βιβλιοθήκες matplotlib.pyplot & seaborn \n",
        "<br>\n",
        "1. Μια οπτικοποίηση που μπορουμε να κάνουμε είναι ένα ιστόγραμμα που να δείχνει **το πλήθος των συναλλαγών ανά ημέρα**. Για αυτό, πρώτα μετατρέπουμε την στήλη recency_days ,που περιέχει έναν int αριθμό, σε format ημερομηνίας και ώρας.\n",
        "Επειδή, δεν έχουμε την αρχική ηερομηνία η συνάρτηση pd.to_datetime() χρησιμοποιεί μια αυθαίρετηημερομηνία. Αυτό δεν παίζει ρόλο στην οπτικοποίηση των δεδομένων, γιατί η στήλη recency_days αντιπροσωπεύει το πλήθος ημερών που πέρασαν από τη μέρα της συναλλαγής. Οπότε για παράδειγμα αν σε δυο συναλλαγές το recency_day είναι 5 τότε και οι δυο αυτές συναλλαγές πραγματοποιήθηκαν την ίδια μέρα, άρα στο ιστόγραμμα θα βρίσκονται στην ίδια \"ράβδο\".\n",
        "<br> \n",
        "Τέλος, μπορούμε να υπλογίσουμε με τον ίδιο τρόπο τον μέσο όρο των συναλλαγών κάθε μέρα.  "
      ],
      "metadata": {
        "id": "CJ6VmG4uV4fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "# recency_days -> datetime format\n",
        "ds['recency_days'] = pd.to_datetime(ds['recency_days'], unit='d')\n",
        "# ιστογραμμα για ρον αριθμο των συναλλαγων καθε μερα\n",
        "plt.hist(ds['recency_days'], bins=100)\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Number of transactions')\n",
        "plt.show()\n",
        "# μο συναλλαγες ανά ημέρα\n",
        "daily_transactions = ds.groupby(ds['recency_days'].dt.date)['basket_value'].mean()\n",
        "print(f\"Mean number of transactions each day: {daily_transactions.mean()} or rounded up: {math.ceil(daily_transactions.mean())}\")"
      ],
      "metadata": {
        "id": "2kAVXc02WD1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Μια δεύτερη αρχική οπτικοποίηση των δεδομένων που μπορεί να γίνει με το dataset είναι να δημιουργήσουμε ένα ιστογραμμα που δείχνει πόσα προϊόντα αγοράζονται συνήθως ανά συναλλαγή. Αρχικά μετράμε πόσες στήλες απο την item_1 - item_32 έχουν τιμή και δεν είναι κενές και φτιάχνουμε το ιστόγραμμα. \n",
        "<br>\n",
        "Παρατηρούμε ότι, οι περισσότεροι καταναλωτές αγοράζουν συνήθως από 1-6 προιόντα."
      ],
      "metadata": {
        "id": "cJG90eqsJTrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# πληθος προιοντων ανα συνναλλαγη\n",
        "c=[]\n",
        "for i, row in ds.iterrows():\n",
        "    count = row.iloc[4:].count()\n",
        "    #print(f\"id: {row['id']} {count} items bought\")\n",
        "    c.append(count)\n",
        "\n",
        "plt.hist(c, bins=100)\n",
        "plt.xlabel(\"Number of items bought\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OYT0BceBJgMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στην συνέχεια πρέπει να κάνουμε μετασχηματισμό των εδομένων σε δυαδική μορφή συναλλαγών.\n",
        "<br> \n",
        "Πρώτα, δημιουργούμε μια λίστα lst  που περιέχει όλα τα ονόματα των προιόντων που αγοράζουν οι καταναλωτές, χωρίς τις nan τιμές και χωρίς διπλότυπα, από τις τιμές που βρίσκονται στις στήλες item_1-item32. Στην συνέχεια ταξινομούμε την λίστα ώστε να έχει αλφαβητική σειρά και τέλος μπορούμε να εμφάνισουμε τον αριθμό των στοιχείων που περιέχει για να ελέγξουμε ότι όλα τα προιόντα έχουν περασθεί στην λίστα.\n",
        "<br> "
      ],
      "metadata": {
        "id": "HfwcGdeQV2-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#κραταμε μονο τις τιμες απο την 3η στηλη κ μετα\n",
        "lst = ds.iloc[:, 3:].values.flatten().tolist()\n",
        "#print(lst)\n",
        "#σβηνουμε τα nan\n",
        "lst = [x for x in lst if not pd.isna(x)]\n",
        "#μοναδικα στοιχια(οχι διπλοτυπα)\n",
        "lst = list(set(lst))\n",
        "print(lst)\n",
        "#print(len(lst))\n",
        "#sort A->z\n",
        "lst.sort()\n",
        "print(lst)\n",
        "print(len(lst))"
      ],
      "metadata": {
        "id": "3YAxZ-io0sEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μετά, δημιουργούμε τον δυαδικό πίνακα σε dataframe όπου κάθε στήλη αποτελεί ένα προιόν και κάθε γραμμή μια συναλλαγή. Σε κάθε κελί τοποθετείται 0 αν το προιόν δεν έχει αγορασθεί και 1 αν έχει αγορασθεί.\n",
        "Τέλος, κρατάμε μόνο τα προιόντα που μας ενιδαφέρουν τα οποία είναι: citrus fruit, tropical fruit, whole milk, other vegetables, rolls/buns, chocolate, bottled water, yogurt,\n",
        "sausage, root vegetables, pastry, sodα, cream. Για κάθε συναλλαγή, βρίσκουμε τα προϊόντα που αγοράστηκαν και για όσα δεν έχουν αγορασθεί βάζουμε 0.\n"
      ],
      "metadata": {
        "id": "RRzCs49UZJLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# κενο dataframe με τον αριθμό των γραμμών του αρχικού dataframe και τον αριθμό των στηλών της λίστας(=169)\n",
        "new_df = pd.DataFrame(0, index=ds.index, columns=lst)\n",
        "# Ορισμός των ονομάτων των στηλών του νέου dataframe ως τα ονόματα των προϊόντων στη λίστα\n",
        "new_df.columns = lst\n",
        "products = list(set(lst))\n",
        "products.sort()\n",
        "# create binary matrix\n",
        "new_df = pd.DataFrame(columns=products)\n",
        "for i, transaction in enumerate(ds.values):\n",
        "    row = [0] * len(products)\n",
        "    for product in products:\n",
        "        if product in transaction:\n",
        "            row[products.index(product)] = 1\n",
        "    new_df.loc[i] = row\n",
        "#print(new_df.head())\n",
        "selected_p = ['citrus fruit', 'tropical fruit', 'whole milk', 'other vegetables', 'rolls/buns', 'chocolate', 'bottled water', 'yogurt', 'sausage', 'root vegetables', 'pastry', 'soda', 'cream']\n",
        "# Δημιουργία νέου dataframe\n",
        "new_df = pd.DataFrame(columns=lst)\n",
        "# Για κάθε συναλλαγή, βρίσκουμε τα προϊόντα που αγοράστηκαν\n",
        "for i in range(len(ds)):\n",
        "    products = ds.iloc[i, 3:].tolist()\n",
        "    products = [p for p in products if p in selected_p]\n",
        "    for product in products:\n",
        "        new_df.at[i, product] = 1\n",
        "# Αντικατάσταση των NaN με 0\n",
        "new_df = new_df.fillna(0)\n",
        "old_df = new_df\n",
        "new_df = new_df[selected_p]\n",
        "new_df.head(n=20)\n"
      ],
      "metadata": {
        "id": "oWChYFygRuFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στο παρακάτω ιστόγραμμα μπορούμε να δούμε την κατανομή των προιόντων που μας ενδιαφέρουν."
      ],
      "metadata": {
        "id": "Ne8PxVEmDU0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογίζουμε τον αριθμό των αγορών που περιλαμβάνουν το κάθε προϊόν\n",
        "counts = new_df.sum().sort_values(ascending=False)[:169]\n",
        "\n",
        "# Δημιουργούμε το διάγραμμα αναλογιών\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "ax.bar(counts.index, counts.values, color='blue')\n",
        "ax.set_title('Most Frequently Bought Items')\n",
        "ax.set_xlabel('Item')\n",
        "ax.set_ylabel('Number of Transactions')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PetODhHtYAPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Τέλος, κάνουμε την διακριτοποίηση των τιμών της στήλης basket_value και οπτικοποιούμε τα αποτελέσματα σε δυο μορφές: ιστόγραμμα και πίτα.\n",
        "Αρχικά, εμφανίζουμε πόσες τιμές περιέχει κάιε στήλη για να ελέγξουμε ότι ειναι περίπου ισοπληθείς. Μετά δημιουργούμε πρώτα ένα bar chart και στην συνέχεια ένα pie chart για την οπτικοποίηση."
      ],
      "metadata": {
        "id": "F8anP9pSdZ_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Διακριτοποίηση της στήλης \"basket_value\" σε τρεις ισοπληθείς κατηγορίες\n",
        "basket_value_bins = pd.qcut(ds['basket_value'], q=3, labels=['low_value_basket', 'medium_value_basket', 'high_value_basket'])\n",
        "ds['basket_category'] = basket_value_bins\n",
        "\n",
        "# Υπολογίζουμε τον αριθμό των αγορών που ανήκουν σε κάθε κατηγορία\n",
        "counts = ds['basket_category'].value_counts()\n",
        "print(counts)\n",
        "# Δημιουργούμε το ιστόγραμμα\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(counts.index, counts.values, color='blue')\n",
        "ax.set_title('Number of Transactions by Basket Category')\n",
        "ax.set_xlabel('Basket Category')\n",
        "ax.set_ylabel('Number of Transactions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Redhq_eTdhNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Οπτικοποίηση ως pie chart\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ax.pie(counts.values, labels=counts.index, autopct='%1.1f%%', startangle=90)\n",
        "ax.set_title('Distribution of Basket Categories')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l1aRiMKrfjJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Άσκηση 2**\n",
        "<br>\n",
        "Μάθηση κανόνων συσχέτισης με την μέθοδο Apriori:\n",
        "<br>\n",
        "i.  Δοκιμάστε την εκτέλεση της μεθόδου Αpriori με διάφορες παραμέτρους για το ελάχιστο\n",
        "Support\n",
        "<br>\n",
        "Πρώτα κάνουμε install το package apyori της python και τις βιβλιοθήκες που θα μας χρειαστούν. Στην συνέχεια φτιάχνουμε μια λίστα που περιέχει τον δυαδικό πίνακα που δημιουργησαμε στοην προηγουμενη ασκηση για να περασθεί ως όρισμα στην συνάρτηση apriori για να βγάλουμε τουςκανόνες.\n",
        "\n"
      ],
      "metadata": {
        "id": "ihquwd9cVvyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apyori"
      ],
      "metadata": {
        "id": "IbMjWfneYGLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals.managers import new_block\n",
        "from apyori import apriori\n",
        "\n",
        "#σειρες και στηλες\n",
        "print(new_df.shape)\n",
        "r=new_df.shape[0]\n",
        "c=new_df.shape[1]\n",
        "\n",
        "# Intializing the list\n",
        "transacts = []\n",
        "#  a list of transactions\n",
        "for i in range(0, r): \n",
        "  transacts.append([str(new_df.values[i,j]) for j in range(0, c)])\n",
        "#print(transacts)\n",
        "# Convert data to list format and run Apriori algorithm\n",
        "transactions = list(transacts)\n",
        "print(transactions)\n",
        "rules = apriori(transactions, min_support=0.03, min_confidence=0.02)\n",
        "list(rules)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IbsuOTAxkYAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# putting output into a pandas dataframe\n",
        "def inspect(output):\n",
        "    lhs         = [tuple(result[2][0][0])[0] for result in output]\n",
        "    rhs         = [tuple(result[2][0][1])[0] for result in output]\n",
        "    support    = [result[1] for result in output]\n",
        "    confidence = [result[2][0][2] for result in output]\n",
        "    lift       = [result[2][0][3] for result in output]\n",
        "    return list(zip(lhs, rhs, support, confidence, lift))\n",
        "output = inspect(rules)\n",
        "output_DataFrame = pd.DataFrame(output, columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
        "#output_DataFrame.head(n=20)\n",
        "print(output_DataFrame)\n",
        "\n"
      ],
      "metadata": {
        "id": "DYe5BRtOpOhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ασκηση 3**\n",
        "Αρχικά, δημιουργουμε ενα dataframe που περιέχει τις 2 πρωτες στήλες που μας ενδιαφέρουν , δηλαδη 'basket_value', 'recency_days'.\n",
        "Στο πρώτο κελί κώδικα έχουμε την εντολή dataf=ds ώστε να σημιουργηθεί ένα copy του dataset για να μπορέσουμε να \"κόψουμε\" απο το αρχικό dataset τις 2 στηλες που μας ενδιαφερουν και να κάνουμε αλλαγές χωρίς να πειράξουμε το αρικό. \n",
        "<br> \n",
        "Για να βεβαιωθουμε οτι τρεχει σωστά ο παρακάτω κώδικας, πρέπει μόλις εμφανιστεί ο πίνακς στην στηλη recencydays να φαίνονται οι ακαιρεοι αριθμοί και όχι ημερομηνίες. Αν φαίνονται ημερομηνίες απλά τρέχουμε ξανά το πρωτο block κώδικα (εκεί που γίνεται το copy του dataset). Και τέλος για να τρέξουμε kmeans χρησιμοπιούμε την βιβλιοθήκη sklearn"
      ],
      "metadata": {
        "id": "7HWtFibuqUdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "selected_cols = ['basket_value', 'recency_days']\n",
        "new_d = dataf[selected_cols]\n",
        "new_d.head(n=10)"
      ],
      "metadata": {
        "id": "lQRnvbqZqZve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στην συνέχεια, σε μια πρωτη αναλαυση, κανουμε κανονικοποιηση στα δεδομένα του παραπάνω πίνακα (new_d) και χρησιμοποιουμε την συναρτηση KMeans() με αριθμό clusters=5 ,συμφωνα με την εκφωνηση. Και τέλος παρουσιάζονται τε κεντρα των 5 ομάδω και τα αποτελεσματα σε ενα γραφημα.\n",
        "<br> \n",
        "Στο γραφημα παρατηρουμε ότι, ενώ καποια clusters έχουν διαχωρισθεί \"σωστα\" υπάρχουν κάποια σημεία όπου μάλλον ανήκουν σε άλλη ομάδα από αυτην που έχουν εισαχθεί."
      ],
      "metadata": {
        "id": "cjNixUwBPLyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# κανονικοποίηση των δεδομένων\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(new_d)\n",
        "\n",
        "# εφαρμογή του αλγορίθμου k-means\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(scaled_data)\n",
        "\n",
        "# εκτύπωση των κέντρων των κλάσεων\n",
        "print(kmeans.cluster_centers_)\n",
        "\n",
        "# παρουσίαση των αποτελεσμάτων σε γράφημα\n",
        "plt.scatter(scaled_data[:, 0], scaled_data[:, 1], c=kmeans.labels_, cmap='rainbow')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], color='black')\n",
        "plt.title('Clustering results')\n",
        "plt.xlabel('Basket value')\n",
        "plt.ylabel('Recency days')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "23LLzo_6N5kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στην συνέχεια, παιρνουμε τα δεδομένα και αφου βγάλουμε τους 5 clusters , κάνουμε τους υπολογισμους των μέσων τιμών και των τυπικών αποκλίσεων των κέντρων των ομάδων\n",
        "<br>\n",
        "Στον παρακάτω κωδικα:\n",
        "<br>\n",
        "Επιλέγουμε τον αριθμό των ομάδων που θέλουμε να δημιουργήσουμε και δημιουργούμε ένα αντικείμενο KMeans με αυτόν τον αριθμό ως παράμετρο.\n",
        "\n",
        "Περνάμε τα δεδομένα μας στον clusterer χρησιμοποιώντας τη μέθοδο fit().\n",
        "\n",
        "Χρησιμοποιούμε τη μέθοδο predict() για να αντιστοιχίσουμε κάθε παρατήρηση στην ομάδα που ανήκει.\n",
        "<br>\n",
        "Στη συνέχεια, μπορούμε να ερμηνεύσουμε κάθε ομάδα μέσω των μέσων τιμών και των τυπικών αποκλίσεων των κέντρων των ομάδων, σε συνδυασμό με την κατανομή των συναλλαγών που ανήκουν σε κάθε ομάδα. Για παράδειγμα, μπορούμε να έχουμε την εξής ερμηνεία των ομάδων:\n",
        "<br>\n",
        " Η Ομάδα 1 και 2 αντιπροσωπεύουν συναλλαγές που έχουν γίνει πρόσφατα, με διαφορετικές αξίες, ενώ η Ομάδα 3 και 4 αντιπροσωπεύουν συναλλαγές με διαφορετικές αξίες που έχουν γίνει παλαιότερα, και η Ομάδα 5 αντιπροσωπεύει συναλλαγές υψηλής αξίας που έχουν γίνει παλαιότερα."
      ],
      "metadata": {
        "id": "qYLJYA1jSc-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = new_d.values\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=20, alpha=1);\n",
        "\n",
        "#τυπ αποκλ & μεση τιμη\n",
        "centers = kmeans.cluster_centers_\n",
        "mean_values = centers.mean(axis=0)\n",
        "std_values = centers.std(axis=0)\n",
        "print(f'centers: {centers} \\n mean values: {mean_values} \\n std values: {std_values}')\n",
        "for i in range(len(centers)):\n",
        "    print(\"Cluster {}: Mean - {}, Standard Deviation - {}\".format(i+1, centers[i], X[y_kmeans == i].std(axis=0)))"
      ],
      "metadata": {
        "id": "MgiJJidhSgZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για το 3ο ερωτημα της ασκησης 3, δημιουργουμε ένα dataframe που περιεέχει τις στηλες basket_value & recency_days και ως έξτρα έχουμε την κατηγορια στην οποια ανηκει καθε συναλλαγη (0-4 αναλογα σε ποιο cluster ειναι) και μια στηλη για καθε cluster οπου εχει 0/1 αναλογα με το αν η συναλλαγη ανηκει σε αυτον η οχι."
      ],
      "metadata": {
        "id": "LDp8cSrCj3a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ανάθεση συναλλαγών σε cluster\n",
        "y_kmeans = kmeans.predict(X)\n",
        "\n",
        "# Δημιουργία νέου χαρακτηριστικού\n",
        "cluster_cols = pd.get_dummies(y_kmeans, prefix='Cluster')\n",
        "\n",
        "# Συνένωση των δύο πίνακων\n",
        "new_d = pd.concat([new_d, cluster_cols], axis=1)\n",
        "\n",
        "# Εμφάνιση των πρώτων 10 συναλλαγών με τα νέα χαρακτηριστικά\n",
        "print(new_d.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "rTZXyvYhiHJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εκπαίδευση του μοντέλου σε συνθετικά δεδομένα."
      ],
      "metadata": {
        "id": "F-YOOsQ9Tq6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm\n",
        "for n_clusters in range(2,10):\n",
        "      # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters value and a random generator\n",
        "    # seed of 10 for reproducibility.\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\n",
        "        \"For n_clusters =\",\n",
        "        n_clusters,\n",
        "        \"The average silhouette_score is :\",\n",
        "        silhouette_avg,\n",
        "    )\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(\n",
        "            np.arange(y_lower, y_upper),\n",
        "            0,\n",
        "            ith_cluster_silhouette_values,\n",
        "            facecolor=color,\n",
        "            edgecolor=color,\n",
        "            alpha=0.7,\n",
        "        )\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(\n",
        "        X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
        "    )\n",
        "\n",
        "    # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(\n",
        "        centers[:, 0],\n",
        "        centers[:, 1],\n",
        "        marker=\"o\",\n",
        "        c=\"white\",\n",
        "        alpha=1,\n",
        "        s=200,\n",
        "        edgecolor=\"k\",\n",
        "    )\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle(\n",
        "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
        "        % n_clusters,\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iidYpQJTHlo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}